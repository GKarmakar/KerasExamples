{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the matplotlib backend\n",
    "import matplotlib\n",
    "matplotlib.use(\"agg\")\n",
    "# import the necessary packages\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import SGD\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import random\n",
    "import pickle\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the argument parser and parse the arguments\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-d\", \"--dataset\", required=True,\n",
    "                help=\"path to input dataset of images\")\n",
    "ap.add_argument(\"-m\", \"--model\", required=True,\n",
    "                help=\"path to output trained model\")\n",
    "ap.add_argument(\"-l\", \"--label-bin\", required=True,\n",
    "                help=\"path to output label binarizer\")\n",
    "ap.add_argument(\"-p\", \"--plot\", required=True,\n",
    "                help=\"path to output accuracy/loss plot\")\n",
    "args = vars(ap.parse_args())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize data and labels\n",
    "print(\"[INFO] loading images..\")\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "#grab the image paths and randmly shuffle them\n",
    "#imagepaths = sorted(list(paths.list_images(args[\"dataset\"])))\n",
    "imagePaths = sorted(list(paths.list_images(\"/Users/trinakarmakar/downloads/keras-tutorial/animals/\")))\n",
    "\n",
    "random.seed(42)\n",
    "random.shuffle(imagePaths)\n",
    "\n",
    "#loop over the inout images\n",
    "for imagePath in imagePaths:\n",
    "    #load the image resize the inage to be 32x32 pixels (ignoring aspect ratio),\n",
    "    #flatten the image unto 32X32#3 = 3027 pixel image\n",
    "    #into a list, and store the image into a data list\n",
    "    image = cv2.imread(imagePath)\n",
    "    image = cv2.resize(image, (32,32)).flatten()\n",
    "    data.append(image)\n",
    "    \n",
    "    #extract the class label from the image and update the \n",
    "    #labels list\n",
    "    label = imagePath.split(os.path.sep)[-2]\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale the raw pixel intensities to the range [0, 1]\n",
    "data = np.array(data, dtype=\"float\") / 255.0\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#partition the data into training and testing splits using 75% of\n",
    "# the data for training and the remaining 25% for testing\n",
    "(X_train, X_test, y_train, y_test) = train_test_split(data, labels, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the labels from integers to vectors (for 2-class binary\n",
    "#classification you should use Keras 'to_categorical' function\n",
    "#instead as the scikit-learn's labelBinarizer will not return a\n",
    "#a vector)\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "y_train = lb.fit_transform(y_train)\n",
    "y_test = lb.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define teh 3072-1074-512-3 architecture using keras\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, input_shape=(3072,), activation='sigmoid'))\n",
    "model.add(Dense(512, activation='sigmoid'))\n",
    "model.add(Dense(len(lb.classes_), activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Intialize our initial learning rate and # of epochs to train for\n",
    "INIT_LR = 0.01\n",
    "EPOCHS=75\n",
    "\n",
    "#Compiling the model using SGD as our optimizer and categotical\n",
    "# cross-entropy loss (you'll want to use binary_crossentropy)\n",
    "#for 2 class classification)\n",
    "\n",
    "print(\"[INFO] training network...\")\n",
    "opt = SGD(lr=INIT_LR)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
    "             metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the neural network\n",
    "history = model.fit(X_train, y_train, \n",
    "                    validation_data=(X_test, y_test),\n",
    "                   epochs=EPOCHS, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the network\n",
    "print(\"[INFO] evaluating the network...\")\n",
    "predictions = model.predict(X_test, batch_size=32)\n",
    "print(classification_report(y_test.argmax(axis=1),\n",
    "                           predictions.argmax(axis=1), \n",
    "                            target_names=lb.classes_))\n",
    "\n",
    "#Plot the training loss and accuracy\n",
    "N = np.arange(0, EPOCHS)\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(N, history.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(N, history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(N, history.history[\"acc\"], label=\"train_acc\")\n",
    "plt.plot(N, history.history[\"val_acc\"], label=\"val_acc\")\n",
    "plt.plot(\"Training loss and accuracy (simlple NN)\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "#plt.savefig(args[\"plot\"])\n",
    "plt.savefig(\"../downloads/acc_report.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the model and label binarizer to disk\n",
    "print(\"[INFO] serializing network and label binarizer...\")\n",
    "#model.save(args[\"model\"])\n",
    "model.save(\"../downloads/image_classification.model\")\n",
    "#f = open(args[\"label_bin\"], \"wb\")\n",
    "f = open(\"../downloads/image_classification_lb.pickle\", \"wb\")\n",
    "f.write(pickle.dumps(lb))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predictions/Inference\n",
    "from keras.models import load_model\n",
    "import argparse\n",
    "import pickle\n",
    "import cv2\n",
    "\n",
    "#construct the argument parser and parse the argumemts\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-i\", \"--image\", required=True,\n",
    "                help=\"path to input image we are going to classify\")\n",
    "ap.add_argument(\"-m\", \"--model\", required=True,\n",
    "                help=\"path to trained Keras model\")\n",
    "ap.add_argument(\"-l\", \"--label-bin\", required=True,\n",
    "                help=\"path to label binarizer\")\n",
    "ap.add_argument(\"-w\", \"--width\", type=int, default=28,\n",
    "                help=\"target spatial dimension width\")\n",
    "ap.add_argument(\"-e\", \"--height\", type=int, default=28,\n",
    "                help=\"target spatial dimension height\")\n",
    "ap.add_argument(\"-f\", \"--flatten\", type=int, default=-1,\n",
    "                help=\"whether or not we should flatten the image\")\n",
    "args = vars(ap.parse_args())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the input image and resize it to the target spatial dimensions\n",
    "#image = cv2.imread(args[\"image\"])\n",
    "image = cv2.imread(\"../downloads/cat.jpg\")\n",
    "output = image.copy()\n",
    "#image = cv2.resize(image, (args[\"width\"], args[\"height\"]))\n",
    "image = cv2.resize(image, (32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check to see if we should flatten the image and add a batch\n",
    "#dimension\n",
    "flatten = 1\n",
    "#if args[\"flatten\"] > 0:\n",
    "if flatten > 0:\n",
    "    image = image.flatten()\n",
    "    image = image.reshape(1, image.shape[0])\n",
    "    \n",
    "#otherwise, we must be working with a CNN, --don't flatten the\n",
    "# image simply add the batch dimension\n",
    "else:\n",
    "    image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the model and labelbinarizer\n",
    "print(\"[INFO] loading network and label binarizer...\")\n",
    "#model = load_model(args[\"model\"])\n",
    "model = load_model(\"../downloads/image_classification.model\")\n",
    "#lb = pickle.loads(open(args[\"label_bin\"], \"rb\").read())\n",
    "lb = pickle.loads(open(\"../downloads/image_classification_lb.pickle\", \"rb\").read())\n",
    "#make a prediction on the image\n",
    "preds = model.predict(image)\n",
    "\n",
    "#find the class label index with the largets corresponding\n",
    "#probability\n",
    "pred_idx = preds.argmax(axis=1)[0]\n",
    "label = lb.classes_[pred_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#draw the class clabel + probability on the output image\n",
    "text = \"{}: {:.2f}%\".format(label, preds[0][pred_idx] * 100)\n",
    "cv2.putText(output, text, (10,30), cv2.FONT_HERSHEY_SIMPLEX, 0.7,\n",
    "           (0, 0, 255), 2)\n",
    "\n",
    "#SHOW THE OUTPUT IMAGE\n",
    "cv2.imshow(\"Image\", output)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Admittedly, using a standard feedforward neural network to classify images is not a wise choice.\n",
    "\n",
    "Instead, we should leverage Convolutional Neural Networks (CNNs) which are designed to operate over the raw pixel intensities of images and learn discriminating filters that can be used to classify images with high accuracy.\n",
    "\n",
    "The model we’ll be discussing here today is a smaller variant of VGGNet which I have named “SmallVGGNet”.\n",
    "\n",
    "VGGNet-like models share two common characteristics:\n",
    "\n",
    "Only 3×3 convolutions are used\n",
    "Convolution layers are stacked on top of each other deeper in the network architecture prior to applying a destructive pooling operation\n",
    "Let’s go ahead and implement SmallVGGNet now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the necessary packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmallVGGNet:\n",
    "    @staticmethod\n",
    "    def build_model(width, height, depth, classes):\n",
    "        #Initialize the model along with the input shape to be\n",
    "        # \"channels last\" and the channels dimension itself.\n",
    "        model = Sequential()\n",
    "        input_shape = (height, width, depth)\n",
    "        chanDim = -1\n",
    "        \n",
    "        #if we are using \"channels first\":\n",
    "        if K.image_data_format() == \"channels_first\":\n",
    "            imput_shape = (depth, height, width)\n",
    "            chanDim = 1\n",
    "        #Now add some layers\n",
    "        model.add(Conv2D(32, (3,3), padding = 'same',\n",
    "                       input_shape = input_shape))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(64, (3,3), padding='same'))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(Conv2D(64, (3,3), padding='same'))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(512))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        #softmax classifier\n",
    "        model.add(dense(classes))\n",
    "        model.add(Activation(\"softmax\"))\n",
    "        \n",
    "        return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# set the matplotlib backend so figures can be saved in the background\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    " \n",
    "# import the necessary packages\n",
    "from smallvggnet import SmallVGGNet\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import SGD\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import random\n",
    "import pickle\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images..\n"
     ]
    }
   ],
   "source": [
    "#initialize data and labels\n",
    "print(\"[INFO] loading images..\")\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "#grab the image paths and randmly shuffle them\n",
    "imagePaths = sorted(list(paths.list_images(\"/Users/trinakarmakar/downloads/keras-tutorial/animals/\")))\n",
    "\n",
    "random.seed(42)\n",
    "random.shuffle(imagePaths)\n",
    "\n",
    "#loop over the inout images\n",
    "for imagePath in imagePaths:\n",
    "    #load the image resize the inage to be 32x32 pixels (ignoring aspect ratio),\n",
    "    #flatten the image unto 32X32#3 = 3027 pixel image\n",
    "    #into a list, and store the image into a data list\n",
    "    image = cv2.imread(imagePath)\n",
    "    image = cv2.resize(image, (64,64))\n",
    "    data.append(image)\n",
    "    \n",
    "    #extract the class label from the image and update the \n",
    "    #labels list\n",
    "    label = imagePath.split(os.path.sep)[-2]\n",
    "    labels.append(label)\n",
    "\n",
    "data = np.array(data, dtype='float') / 255.0\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, X_test, y_train, y_test) = train_test_split(data, labels, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelBinarizer()\n",
    "y_train = lb.fit_transform(y_train)\n",
    "y_test = lb.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = ImageDataGenerator(rotation_range=30,\n",
    "                        width_shift_range=0.1,\n",
    "                        height_shift_range=0.1,\n",
    "                        shear_range=0.2,\n",
    "                        zoom_range=0.2,\n",
    "                        horizontal_flip = True,\n",
    "                        fill_mode = \"nearest\")\n",
    "\n",
    "#Initialize our VGG like CNN\n",
    "model = SmallVGGNet.build_model(width=64, height=64, depth=3, \n",
    "                                classes=len(lb.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training network...\n",
      "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n",
      "Epoch 1/75\n",
      "79/79 [==============================] - 135s 2s/step - loss: 1.2566 - acc: 0.5156 - val_loss: 1.3975 - val_acc: 0.5356\n",
      "Epoch 2/75\n",
      "79/79 [==============================] - 130s 2s/step - loss: 0.9586 - acc: 0.6041 - val_loss: 1.0616 - val_acc: 0.5489\n",
      "Epoch 3/75\n",
      "79/79 [==============================] - 121s 2s/step - loss: 0.8463 - acc: 0.6146 - val_loss: 1.2536 - val_acc: 0.4778\n",
      "Epoch 4/75\n",
      "79/79 [==============================] - 121s 2s/step - loss: 0.7419 - acc: 0.6389 - val_loss: 0.8866 - val_acc: 0.6222\n",
      "Epoch 5/75\n",
      "79/79 [==============================] - 121s 2s/step - loss: 0.7334 - acc: 0.6582 - val_loss: 1.2058 - val_acc: 0.5089\n",
      "Epoch 6/75\n",
      "79/79 [==============================] - 121s 2s/step - loss: 0.7172 - acc: 0.6607 - val_loss: 0.6663 - val_acc: 0.6778\n",
      "Epoch 7/75\n",
      "79/79 [==============================] - 121s 2s/step - loss: 0.6709 - acc: 0.6785 - val_loss: 0.7148 - val_acc: 0.6933\n",
      "Epoch 8/75\n",
      "79/79 [==============================] - 4913s 62s/step - loss: 0.6550 - acc: 0.6989 - val_loss: 0.6106 - val_acc: 0.7156\n",
      "Epoch 9/75\n",
      "79/79 [==============================] - 12991s 164s/step - loss: 0.6420 - acc: 0.6828 - val_loss: 0.6368 - val_acc: 0.7222\n",
      "Epoch 10/75\n",
      "79/79 [==============================] - 12598s 159s/step - loss: 0.6085 - acc: 0.7196 - val_loss: 1.0609 - val_acc: 0.5933\n",
      "Epoch 11/75\n",
      "79/79 [==============================] - 2756s 35s/step - loss: 0.6067 - acc: 0.7172 - val_loss: 0.6383 - val_acc: 0.7178\n",
      "Epoch 12/75\n",
      "79/79 [==============================] - 138s 2s/step - loss: 0.5852 - acc: 0.7165 - val_loss: 0.5758 - val_acc: 0.7467\n",
      "Epoch 13/75\n",
      "79/79 [==============================] - 127s 2s/step - loss: 0.5885 - acc: 0.7199 - val_loss: 0.5809 - val_acc: 0.7422\n",
      "Epoch 14/75\n",
      "79/79 [==============================] - 119s 2s/step - loss: 0.5726 - acc: 0.7368 - val_loss: 0.7756 - val_acc: 0.6933\n",
      "Epoch 15/75\n",
      "79/79 [==============================] - 120s 2s/step - loss: 0.5858 - acc: 0.7205 - val_loss: 0.6252 - val_acc: 0.7067\n",
      "Epoch 16/75\n",
      "79/79 [==============================] - 120s 2s/step - loss: 0.5518 - acc: 0.7392 - val_loss: 0.9631 - val_acc: 0.6378\n",
      "Epoch 17/75\n",
      "79/79 [==============================] - 120s 2s/step - loss: 0.5694 - acc: 0.7266 - val_loss: 0.6397 - val_acc: 0.7222\n",
      "Epoch 18/75\n",
      "79/79 [==============================] - 121s 2s/step - loss: 0.5443 - acc: 0.7505 - val_loss: 0.6056 - val_acc: 0.7333\n",
      "Epoch 19/75\n",
      "79/79 [==============================] - 3027s 38s/step - loss: 0.5456 - acc: 0.7473 - val_loss: 0.5473 - val_acc: 0.7444\n",
      "Epoch 20/75\n",
      "79/79 [==============================] - 242s 3s/step - loss: 0.5390 - acc: 0.7505 - val_loss: 0.6013 - val_acc: 0.7422\n",
      "Epoch 21/75\n",
      "79/79 [==============================] - 137s 2s/step - loss: 0.5479 - acc: 0.7395 - val_loss: 0.7516 - val_acc: 0.7044\n",
      "Epoch 22/75\n",
      "79/79 [==============================] - 125s 2s/step - loss: 0.5244 - acc: 0.7591 - val_loss: 0.5796 - val_acc: 0.7467\n",
      "Epoch 23/75\n",
      "79/79 [==============================] - 129s 2s/step - loss: 0.5194 - acc: 0.7531 - val_loss: 0.6001 - val_acc: 0.7467\n",
      "Epoch 24/75\n",
      "79/79 [==============================] - 156s 2s/step - loss: 0.5288 - acc: 0.7554 - val_loss: 0.5862 - val_acc: 0.7356\n",
      "Epoch 25/75\n",
      "79/79 [==============================] - 144s 2s/step - loss: 0.4984 - acc: 0.7695 - val_loss: 0.6017 - val_acc: 0.7222\n",
      "Epoch 26/75\n",
      "79/79 [==============================] - 135s 2s/step - loss: 0.5118 - acc: 0.7665 - val_loss: 0.6464 - val_acc: 0.7089\n",
      "Epoch 27/75\n",
      "79/79 [==============================] - 126s 2s/step - loss: 0.5153 - acc: 0.7630 - val_loss: 0.6672 - val_acc: 0.7133\n",
      "Epoch 28/75\n",
      "79/79 [==============================] - 131s 2s/step - loss: 0.4816 - acc: 0.7761 - val_loss: 0.9576 - val_acc: 0.6467\n",
      "Epoch 29/75\n",
      "79/79 [==============================] - 145s 2s/step - loss: 0.5058 - acc: 0.7670 - val_loss: 0.6676 - val_acc: 0.7111\n",
      "Epoch 30/75\n",
      "79/79 [==============================] - 123s 2s/step - loss: 0.4978 - acc: 0.7667 - val_loss: 0.5236 - val_acc: 0.7711\n",
      "Epoch 31/75\n",
      "79/79 [==============================] - 123s 2s/step - loss: 0.5014 - acc: 0.7633 - val_loss: 0.5709 - val_acc: 0.7578\n",
      "Epoch 32/75\n",
      "79/79 [==============================] - 144s 2s/step - loss: 0.4850 - acc: 0.7764 - val_loss: 0.6297 - val_acc: 0.7111\n",
      "Epoch 33/75\n",
      "79/79 [==============================] - 148s 2s/step - loss: 0.4959 - acc: 0.7682 - val_loss: 0.5868 - val_acc: 0.7333\n",
      "Epoch 34/75\n",
      "79/79 [==============================] - 137s 2s/step - loss: 0.4709 - acc: 0.7892 - val_loss: 0.6129 - val_acc: 0.7467\n",
      "Epoch 35/75\n",
      "79/79 [==============================] - 130s 2s/step - loss: 0.4583 - acc: 0.7943 - val_loss: 0.6131 - val_acc: 0.7244\n",
      "Epoch 36/75\n",
      "79/79 [==============================] - 130s 2s/step - loss: 0.4908 - acc: 0.7741 - val_loss: 0.6396 - val_acc: 0.7111\n",
      "Epoch 37/75\n",
      "79/79 [==============================] - 138s 2s/step - loss: 0.4559 - acc: 0.7923 - val_loss: 0.5843 - val_acc: 0.7400\n",
      "Epoch 38/75\n",
      "79/79 [==============================] - 134s 2s/step - loss: 0.4802 - acc: 0.7855 - val_loss: 0.7011 - val_acc: 0.7022\n",
      "Epoch 39/75\n",
      "79/79 [==============================] - 132s 2s/step - loss: 0.4425 - acc: 0.7947 - val_loss: 0.6932 - val_acc: 0.7133\n",
      "Epoch 40/75\n",
      "79/79 [==============================] - 146s 2s/step - loss: 0.4510 - acc: 0.8011 - val_loss: 0.6513 - val_acc: 0.7200\n",
      "Epoch 41/75\n",
      "79/79 [==============================] - 140s 2s/step - loss: 0.4707 - acc: 0.7795 - val_loss: 0.6302 - val_acc: 0.7333\n",
      "Epoch 42/75\n",
      "79/79 [==============================] - 139s 2s/step - loss: 0.4285 - acc: 0.8019 - val_loss: 0.7641 - val_acc: 0.6778\n",
      "Epoch 43/75\n",
      "79/79 [==============================] - 139s 2s/step - loss: 0.4495 - acc: 0.7977 - val_loss: 0.7044 - val_acc: 0.7222\n",
      "Epoch 44/75\n",
      "79/79 [==============================] - 141s 2s/step - loss: 0.4523 - acc: 0.7949 - val_loss: 0.5521 - val_acc: 0.7556\n",
      "Epoch 45/75\n",
      "79/79 [==============================] - 138s 2s/step - loss: 0.4147 - acc: 0.8072 - val_loss: 0.5563 - val_acc: 0.7578\n",
      "Epoch 46/75\n",
      "79/79 [==============================] - 133s 2s/step - loss: 0.4562 - acc: 0.7930 - val_loss: 0.5285 - val_acc: 0.7756\n",
      "Epoch 47/75\n",
      "79/79 [==============================] - 133s 2s/step - loss: 0.4538 - acc: 0.7911 - val_loss: 1.0167 - val_acc: 0.6533\n",
      "Epoch 48/75\n",
      "79/79 [==============================] - 131s 2s/step - loss: 0.4224 - acc: 0.8085 - val_loss: 0.5519 - val_acc: 0.7578\n",
      "Epoch 49/75\n",
      "79/79 [==============================] - 151s 2s/step - loss: 0.4196 - acc: 0.8176 - val_loss: 0.6897 - val_acc: 0.7267\n",
      "Epoch 50/75\n",
      "79/79 [==============================] - 136s 2s/step - loss: 0.4220 - acc: 0.8139 - val_loss: 0.5870 - val_acc: 0.7400\n",
      "Epoch 51/75\n",
      "79/79 [==============================] - 132s 2s/step - loss: 0.4371 - acc: 0.8104 - val_loss: 1.1363 - val_acc: 0.6356\n",
      "Epoch 52/75\n",
      "79/79 [==============================] - 132s 2s/step - loss: 0.4222 - acc: 0.8112 - val_loss: 0.7583 - val_acc: 0.7022\n",
      "Epoch 53/75\n",
      "79/79 [==============================] - 138s 2s/step - loss: 0.4262 - acc: 0.8102 - val_loss: 0.5089 - val_acc: 0.7733\n",
      "Epoch 54/75\n",
      "79/79 [==============================] - 137s 2s/step - loss: 0.4060 - acc: 0.8126 - val_loss: 0.7040 - val_acc: 0.7400\n",
      "Epoch 55/75\n",
      "79/79 [==============================] - 141s 2s/step - loss: 0.4233 - acc: 0.8051 - val_loss: 0.6265 - val_acc: 0.7467\n",
      "Epoch 56/75\n",
      "79/79 [==============================] - 152s 2s/step - loss: 0.3983 - acc: 0.8225 - val_loss: 0.8620 - val_acc: 0.7000\n",
      "Epoch 57/75\n",
      "79/79 [==============================] - 140s 2s/step - loss: 0.4060 - acc: 0.8132 - val_loss: 0.9232 - val_acc: 0.6889\n",
      "Epoch 58/75\n",
      "79/79 [==============================] - 139s 2s/step - loss: 0.4364 - acc: 0.7991 - val_loss: 0.6428 - val_acc: 0.7511\n",
      "Epoch 59/75\n",
      "79/79 [==============================] - 143s 2s/step - loss: 0.4395 - acc: 0.7982 - val_loss: 0.9700 - val_acc: 0.6689\n",
      "Epoch 60/75\n",
      "79/79 [==============================] - 122s 2s/step - loss: 0.3971 - acc: 0.8310 - val_loss: 0.8540 - val_acc: 0.6978\n",
      "Epoch 61/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 120s 2s/step - loss: 0.3965 - acc: 0.8252 - val_loss: 0.6388 - val_acc: 0.7444\n",
      "Epoch 62/75\n",
      "79/79 [==============================] - 120s 2s/step - loss: 0.4005 - acc: 0.8264 - val_loss: 0.5969 - val_acc: 0.7556\n",
      "Epoch 63/75\n",
      "79/79 [==============================] - 120s 2s/step - loss: 0.4110 - acc: 0.8221 - val_loss: 0.5639 - val_acc: 0.7844\n",
      "Epoch 64/75\n",
      "79/79 [==============================] - 119s 2s/step - loss: 0.4060 - acc: 0.8243 - val_loss: 0.5370 - val_acc: 0.7733\n",
      "Epoch 65/75\n",
      "79/79 [==============================] - 2355s 30s/step - loss: 0.3875 - acc: 0.8284 - val_loss: 0.6751 - val_acc: 0.7533\n",
      "Epoch 66/75\n",
      "79/79 [==============================] - 11012s 139s/step - loss: 0.3923 - acc: 0.8252 - val_loss: 0.6118 - val_acc: 0.7644\n",
      "Epoch 67/75\n",
      "79/79 [==============================] - 2488s 31s/step - loss: 0.3888 - acc: 0.8240 - val_loss: 0.8795 - val_acc: 0.6956\n",
      "Epoch 68/75\n",
      "79/79 [==============================] - 137s 2s/step - loss: 0.4055 - acc: 0.8237 - val_loss: 0.5676 - val_acc: 0.7756\n",
      "Epoch 69/75\n",
      "79/79 [==============================] - 148s 2s/step - loss: 0.3916 - acc: 0.8228 - val_loss: 0.6845 - val_acc: 0.7422\n",
      "Epoch 70/75\n",
      "79/79 [==============================] - 126s 2s/step - loss: 0.3680 - acc: 0.8353 - val_loss: 0.4947 - val_acc: 0.7867\n",
      "Epoch 71/75\n",
      "79/79 [==============================] - 127s 2s/step - loss: 0.3759 - acc: 0.8298 - val_loss: 0.5385 - val_acc: 0.7889\n",
      "Epoch 72/75\n",
      "79/79 [==============================] - 128s 2s/step - loss: 0.3787 - acc: 0.8322 - val_loss: 0.5697 - val_acc: 0.7667\n",
      "Epoch 73/75\n",
      "79/79 [==============================] - 125s 2s/step - loss: 0.3798 - acc: 0.8329 - val_loss: 0.8719 - val_acc: 0.7044\n",
      "Epoch 74/75\n",
      "79/79 [==============================] - 131s 2s/step - loss: 0.3793 - acc: 0.8276 - val_loss: 0.6219 - val_acc: 0.7600\n",
      "Epoch 75/75\n",
      "79/79 [==============================] - 129s 2s/step - loss: 0.3700 - acc: 0.8383 - val_loss: 0.6561 - val_acc: 0.7444\n"
     ]
    }
   ],
   "source": [
    "# initialize our initial learning rate, # of epochs to train for,\n",
    "# and batch size\n",
    "INIT_LR = 0.01\n",
    "EPOCHS = 75\n",
    "BS = 32\n",
    " \n",
    "# initialize the model and optimizer (you'll want to use\n",
    "# binary_crossentropy for 2-class classification)\n",
    "print(\"[INFO] training network...\")\n",
    "opt = SGD(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])\n",
    " \n",
    "# train the network\n",
    "history = model.fit_generator(aug.flow(X_train, y_train, batch_size=BS), \n",
    "                              validation_data=(X_test, y_test), \n",
    "                              steps_per_epoch=len(X_train) // BS,epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO] evaluating network...\")\n",
    "predictions = model.predict(X_test, batch_size=32)\n",
    "print(classification_report(y_test.argmax(axis=1),\n",
    "                            predictions.argmax(axis=1), \n",
    "                            target_names=lb.classes_))\n",
    " \n",
    "# plot the training loss and accuracy\n",
    "N = np.arange(0, EPOCHS)\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(N, history.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(N, history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(N, history.history[\"acc\"], label=\"train_acc\")\n",
    "plt.plot(N, history.history[\"val_acc\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy (SmallVGGNet)\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend()\n",
    "plt.savefig(\"../downloads/acc_report_cnn.png\")\n",
    " \n",
    "# save the model and label binarizer to disk\n",
    "print(\"[INFO] serializing network and label binarizer...\")\n",
    "model.save(\"image_classification_cnn.model\")\n",
    "f = open(args[\"../downloads/image_classification_CNN_lb.pickle\", \"wb\")\n",
    "f.write(pickle.dumps(lb))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
